
# 卷积神经网络

## 卷积层 Convolution Layer

图像识别的特点：
* 特征具有局部性
* 特征可能出现在任何位置
* 下采样图像，不会改变图像目标


1.特征具有局部性：卷积核每次仅连接K*K区域，K*K是卷积核尺寸
![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/conv1.png)

局部连接的好处，是减少了参数的数量，从而减少了计算复杂度。
特征也存在局部性，不需要看整张图片

2.特征可能出现在任何位置:卷积核参数重复使用(参数共享)，在图像上滑动。
![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/conv2.png)

### 卷积核 kernel：具可学习参数的算子，用于对输入图像进行特征提取，输出通常称为特征图(feature maps)
![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/kernel.png)

2012年AlexNet网络第一个卷积层卷积核可视化卷积核呈现边缘，频率和色彩上的特征模式
![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/featuremap.png)

### 填充 padding: 在输入图像的周围添加额外的行/列
作用：
* 使卷积后图像分辨率不变，方便计算特征图尺寸的变化
* 弥补边界信息 "丢失"

padding = 1

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/padding.png)


### 步幅 Stride: 卷积核滑动的行数和列数称为步幅，控制输出特征图的大小，会被缩小1/s倍

卷积到了边缘不满足kernel size的时候会向下取整，即使是有图像信息，也会抛弃(即向下取整)

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/stride.png)

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/stride2.png)

Fo: 表示输出特征图的size

Fin: 输入特征图size

k: kernel size，卷积核的大小

p: padding的大小，之所以要乘以2，是因为左右都有padding

s: stride，步长，其中步长对图像分辨率的改变起了主要的作用

计算结束之后要+1，因为一开始的时候有一个像素


### 多通道卷积:
RGB 图像是3* h *w的三维数据，第一个维度3，表示channel，通道数。一个卷积核是3-D张量，第一个维度与输入通道有关。注：卷积核尺寸通常指高、宽.

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/channel.png)

X = 2 * 3 * 3 (输入通道数 * 输入宽 * 输入高)<br>
W = 1 * 2 * 2  * 2 (输出通道数 * 输入通道数* 卷积核高 * 卷积核宽) <br>
Y = 1 * 2 * 2 (输出通道数 * 输出特征图高 * 输出特征图宽) 


## 池化层 Pooling Layer
池化：一个像素表示一块区域的像素值，降低图像分辨率

一块像素区域如何被一个像素代替：

方法1: Max Pooling, 取最大值
方法2: Average Pooling，取平均值

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/pooling.png)

输出尺寸计算与卷积操作类似

注意池化层可以无学习参数

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/pooling2.png)