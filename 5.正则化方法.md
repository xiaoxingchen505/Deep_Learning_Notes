

# 正则化方法

Regularization: 减小方差的策略，通俗理解为减轻过拟合的策略

误差可分解为：偏差，方差与噪声之和。即误差 = 偏差 + 方差 + 噪音之和

偏差：度量了学习算法的期望侧与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。

方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响

噪声: 则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/r1.png)

## 过拟合现象：
![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/r2.png)


![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/r3.png)

## 权值衰减

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/r4.png)


## 使用 dropout

![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/dropout.png)


## 其他正则化方法：
![image](https://github.com/xiaoxingchen505/Deep_Learning_Notes/blob/master/images/r5.png)
